{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSpyder Editor\\n\\nThis is a temporary script file.\\n'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "#%%\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random as rn\n",
    "import matplotlib.pyplot as plt; \n",
    " \n",
    "# Importing sklearn libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    " \n",
    "# Importing hypopt library for grid search\n",
    "#from hypopt import GridSearch\n",
    " \n",
    "# Importing Keras libraries\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import urllib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "#for multiple outs from single cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 418 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 17s 2s/step - loss: 0.6779 - acc: 0.6024 - val_loss: 0.7036 - val_acc: 0.5550\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6657 - acc: 0.5973 - val_loss: 0.6647 - val_acc: 0.5575\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.6470 - acc: 0.6283 - val_loss: 0.6045 - val_acc: 0.7025\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 8s 956ms/step - loss: 0.5578 - acc: 0.7228 - val_loss: 0.5899 - val_acc: 0.7200\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.5224 - acc: 0.7368 - val_loss: 0.5618 - val_acc: 0.7300\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.5228 - acc: 0.7239 - val_loss: 0.5759 - val_acc: 0.7225\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4885 - acc: 0.7675 - val_loss: 0.6137 - val_acc: 0.7025\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4589 - acc: 0.8036 - val_loss: 0.5953 - val_acc: 0.7300\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 8s 998ms/step - loss: 0.4469 - acc: 0.7925 - val_loss: 0.5427 - val_acc: 0.7450\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.4172 - acc: 0.8241 - val_loss: 0.5590 - val_acc: 0.7500\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3599 - acc: 0.8536 - val_loss: 0.6010 - val_acc: 0.7350\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4171 - acc: 0.8050 - val_loss: 0.7125 - val_acc: 0.6750\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.3934 - acc: 0.8168 - val_loss: 0.6370 - val_acc: 0.7350\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 8s 947ms/step - loss: 0.3491 - acc: 0.8454 - val_loss: 0.5302 - val_acc: 0.7450\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.3143 - acc: 0.8695 - val_loss: 0.6002 - val_acc: 0.7400\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3293 - acc: 0.8468 - val_loss: 0.8325 - val_acc: 0.7125\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2951 - acc: 0.8770 - val_loss: 0.6797 - val_acc: 0.6900\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.2813 - acc: 0.8900 - val_loss: 0.7528 - val_acc: 0.7150\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 8s 981ms/step - loss: 0.2216 - acc: 0.9075 - val_loss: 0.7713 - val_acc: 0.7100\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2310 - acc: 0.9065 - val_loss: 0.6894 - val_acc: 0.7325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f09417fdf60>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = './MobileImages/data4ImageGen/'\n",
    "#Rename Files in Each Folder if necessary & sync to single folder trainData\n",
    "#find minor/ -type f -exec  sh -c 'mv {} $(dirname {})/$(basename $(dirname {}))_$(basename {})' \\;\n",
    "#rsync -a moderate/ trainData/\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=2,\n",
    "    #width_shift_range=0.25,\n",
    "    #height_shift_range=0.25,\n",
    "    rescale=1/255,\n",
    "    #shear_range=0.22,\n",
    "    zoom_range=0.25,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.25\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    ")\n",
    "\n",
    "# I found that a batch size of 128 offers the best trade-off between\n",
    "# model training time and batch volatility.\n",
    "batch_size = 50\n",
    "\n",
    "# Notice the tiny target size, just 48x48!\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    img_dir + 'training/',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    img_dir + 'validation/',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# define the model\n",
    "prior = keras.applications.VGG16(\n",
    "    include_top=False, \n",
    "    weights='imagenet',\n",
    "    input_shape=(48, 48 , 3)\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(prior)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax', name='Output'))\n",
    " \n",
    "# freeze the vgg16 model\n",
    "for cnn_block_layer in model.layers[0].layers:\n",
    "    cnn_block_layer.trainable = False\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(train_generator.filenames) // batch_size,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=7 , restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# save model artifact\n",
    "model.save('./SavedModels/model-48.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 418 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 33s 4s/step - loss: 0.7776 - acc: 0.4801 - val_loss: 0.7010 - val_acc: 0.5400\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 27s 3s/step - loss: 0.7133 - acc: 0.5250 - val_loss: 0.6865 - val_acc: 0.5400\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 23s 3s/step - loss: 0.7010 - acc: 0.5207 - val_loss: 0.6761 - val_acc: 0.6725\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.6888 - acc: 0.5505 - val_loss: 0.6636 - val_acc: 0.6825\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.6869 - acc: 0.5058 - val_loss: 0.6532 - val_acc: 0.6250\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 27s 3s/step - loss: 0.6641 - acc: 0.5825 - val_loss: 0.6370 - val_acc: 0.6275\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.6517 - acc: 0.6031 - val_loss: 0.6282 - val_acc: 0.6550\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.7036 - acc: 0.5292 - val_loss: 0.6270 - val_acc: 0.5800\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.7143 - acc: 0.5227 - val_loss: 0.6821 - val_acc: 0.5625\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.6949 - acc: 0.5158 - val_loss: 0.6798 - val_acc: 0.6225\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 27s 3s/step - loss: 0.6907 - acc: 0.5350 - val_loss: 0.6762 - val_acc: 0.5525\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 24s 3s/step - loss: 0.6711 - acc: 0.5773 - val_loss: 0.6599 - val_acc: 0.5775\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 27s 3s/step - loss: 0.6539 - acc: 0.6150 - val_loss: 0.6278 - val_acc: 0.6575\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 24s 3s/step - loss: 0.6381 - acc: 0.6174 - val_loss: 0.6324 - val_acc: 0.6050\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 27s 3s/step - loss: 0.6683 - acc: 0.5850 - val_loss: 0.6384 - val_acc: 0.6550\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 28s 3s/step - loss: 0.6713 - acc: 0.6106 - val_loss: 0.6486 - val_acc: 0.6425\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.6698 - acc: 0.5887 - val_loss: 0.6215 - val_acc: 0.6675\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 25s 3s/step - loss: 0.6276 - acc: 0.6319 - val_loss: 0.6081 - val_acc: 0.6500\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.6276 - acc: 0.6250 - val_loss: 0.6823 - val_acc: 0.5875\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 24s 3s/step - loss: 0.6761 - acc: 0.5315 - val_loss: 0.6096 - val_acc: 0.6525\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# define data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    #width_shift_range=0.25,\n",
    "    #height_shift_range=0.25,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    #zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.25\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    img_dir + 'training/',\n",
    "    target_size=(96, 96),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    img_dir + 'validation/',\n",
    "    target_size=(96, 96),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, dilation_rate=2, kernel_size=(3, 3), input_shape=(96, 96, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(Conv2D(64, dilation_rate=2, kernel_size=(3, 3), input_shape=(96, 96, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "# load the pretrained model\n",
    "prior = load_model('./SavedModels/model-48.h5')\n",
    "\n",
    "# add all but the first two layers of VGG16 to the new model\n",
    "# strip the input layer out, this is now 96x96\n",
    "# also strip out the first convolutional layer, this took the 48x48 input and convolved it but\n",
    "# this is now the job of the three new layers.\n",
    "for layer in prior.layers[0].layers[2:]:\n",
    "    model.add(layer)\n",
    "\n",
    "# re-add the feedforward layers on top\n",
    "for layer in prior.layers[1:]:\n",
    "    model.add(layer)\n",
    "\n",
    "# the pretrained CNN layers are already marked non-trainable mark off the top layers as well\n",
    "for layer in prior.layers[-4:]:\n",
    "     layer.trainable = False\n",
    "    \n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(train_generator.filenames) // batch_size,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save model artifact\n",
    "model.save('./SavedModels/model-96.h5')\n",
    "# with open('./SavedModels/model-96-history.pickle', 'wb') as fp:\n",
    "#         pickle.dump(history.history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 418 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n",
      "Found 52 images belonging to 1 classes.\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 67s 8s/step - loss: 0.7133 - acc: 0.4506 - val_loss: 0.6893 - val_acc: 0.5400\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.6910 - acc: 0.5418 - val_loss: 0.6891 - val_acc: 0.5400\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 58s 7s/step - loss: 0.6944 - acc: 0.5126 - val_loss: 0.6914 - val_acc: 0.5375\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.6892 - acc: 0.5725 - val_loss: 0.6866 - val_acc: 0.5525\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 54s 7s/step - loss: 0.6889 - acc: 0.5102 - val_loss: 0.6782 - val_acc: 0.5550\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 62s 8s/step - loss: 0.6753 - acc: 0.5675 - val_loss: 0.6489 - val_acc: 0.6550\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 54s 7s/step - loss: 0.6714 - acc: 0.5717 - val_loss: 0.6246 - val_acc: 0.6625\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.6725 - acc: 0.5850 - val_loss: 0.6784 - val_acc: 0.5650\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.6901 - acc: 0.5645 - val_loss: 0.6431 - val_acc: 0.5800\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 60s 7s/step - loss: 0.6577 - acc: 0.6248 - val_loss: 0.6433 - val_acc: 0.6175\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 55s 7s/step - loss: 0.6675 - acc: 0.5768 - val_loss: 0.6452 - val_acc: 0.5825\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.6546 - acc: 0.5875 - val_loss: 0.6542 - val_acc: 0.5975\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.6469 - acc: 0.6305 - val_loss: 0.5967 - val_acc: 0.7075\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.6593 - acc: 0.5754 - val_loss: 0.6352 - val_acc: 0.6675\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 53s 7s/step - loss: 0.6246 - acc: 0.6381 - val_loss: 0.5849 - val_acc: 0.6900\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.6024 - acc: 0.6925 - val_loss: 0.5972 - val_acc: 0.6950\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.6049 - acc: 0.6650 - val_loss: 0.6027 - val_acc: 0.6775\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.5958 - acc: 0.6882 - val_loss: 0.5545 - val_acc: 0.7350\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.5957 - acc: 0.6878 - val_loss: 0.5513 - val_acc: 0.7275\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 58s 7s/step - loss: 0.5920 - acc: 0.6734 - val_loss: 0.5622 - val_acc: 0.7100\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# define data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    #width_shift_range=0.25,\n",
    "    #height_shift_range=0.25,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    #zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.25\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    img_dir + 'training/',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    img_dir + 'validation/',\n",
    "    target_size=(192, 192),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory= img_dir + 'testing/',\n",
    "    target_size=(192, 192),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(192, 192, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# load the pretrained model\n",
    "prior = load_model('./SavedModels/model-96.h5')\n",
    "\n",
    "# add all but the first two layers of VGG16 to the new model\n",
    "# strip the input layer out, this is now 96x96\n",
    "# also strip out the first convolutional layer, this took the 96x96 input and convolved it but\n",
    "# this is now the job of the three new layers.dany\n",
    "for layer in prior.layers[1:]:\n",
    "    layer.name += '_prior'  # set layer names to avoid name collisions\n",
    "    model.add(layer)\n",
    "\n",
    "# the pretrained CNN layers are already marked non-trainable\n",
    "# mark off the top layers as well\n",
    "for layer in prior.layers[-4:]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")  \n",
    "\n",
    "# fit the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator.filenames) // batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(train_generator.filenames) // batch_size,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save model artifact\n",
    "model.save('./SavedModels/model-192.h5')\n",
    "# with open('./SavedModels/model-96-history.pickle', 'wb') as fp:\n",
    "#         pickle.dump(history.history, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5740638822317123, 0.6825000122189522]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_VALID = len(train_generator.filenames) // batch_size\n",
    "model.evaluate_generator(generator=validation_generator,steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 images belonging to 1 classes.\n",
      "52/52 [==============================] - 6s 111ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    img_dir + 'testing/',\n",
    "    target_size=(192, 192),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")  \n",
    "\n",
    "STEP_SIZE_TEST=len(test_generator.filenames) // test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)\n",
    "\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/Damage_327-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/Damage_332-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/Damage_335-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/Damage_341-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/Damage_342-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test/Damage_345-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test/Damage_348-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test/Damage_354-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test/Damage_355-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test/Damage_364-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test/Damage_365-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test/Damage_372-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test/Damage_377-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test/Damage_379-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test/Damage_386-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test/Damage_387-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test/Damage_389-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test/Damage_394-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test/Damage_400-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test/Damage_404-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test/Damage_405-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test/Damage_410-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test/Damage_415-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test/Damage_420-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test/Damage_999-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test/NoDamage_106-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test/NoDamage_116-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test/NoDamage_154-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test/NoDamage_162-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test/NoDamage_169-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>test/NoDamage_176-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>test/NoDamage_182-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>test/NoDamage_191-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>test/NoDamage_197-Copy1.png</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>test/NoDamage_205-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>test/NoDamage_208-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>test/NoDamage_210-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>test/NoDamage_220-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>test/NoDamage_24-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>test/NoDamage_31-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>test/NoDamage_36-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>test/NoDamage_41-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>test/NoDamage_45-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>test/NoDamage_51-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>test/NoDamage_60-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>test/NoDamage_65-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>test/NoDamage_70-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>test/NoDamage_77-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>test/NoDamage_84-Copy1.jpg</td>\n",
       "      <td>Damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>test/NoDamage_90-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>test/NoDamage_98-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>test/NoDamage_998-Copy1.jpg</td>\n",
       "      <td>NoDamage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Filename Predictions\n",
       "0     test/Damage_327-Copy1.jpg      Damage\n",
       "1     test/Damage_332-Copy1.jpg    NoDamage\n",
       "2     test/Damage_335-Copy1.jpg    NoDamage\n",
       "3     test/Damage_341-Copy1.jpg    NoDamage\n",
       "4     test/Damage_342-Copy1.jpg    NoDamage\n",
       "5     test/Damage_345-Copy1.jpg      Damage\n",
       "6     test/Damage_348-Copy1.jpg      Damage\n",
       "7     test/Damage_354-Copy1.jpg    NoDamage\n",
       "8     test/Damage_355-Copy1.jpg    NoDamage\n",
       "9     test/Damage_364-Copy1.jpg      Damage\n",
       "10    test/Damage_365-Copy1.jpg    NoDamage\n",
       "11    test/Damage_372-Copy1.jpg    NoDamage\n",
       "12    test/Damage_377-Copy1.jpg    NoDamage\n",
       "13    test/Damage_379-Copy1.jpg    NoDamage\n",
       "14    test/Damage_386-Copy1.jpg      Damage\n",
       "15    test/Damage_387-Copy1.jpg    NoDamage\n",
       "16    test/Damage_389-Copy1.jpg      Damage\n",
       "17    test/Damage_394-Copy1.jpg    NoDamage\n",
       "18    test/Damage_400-Copy1.jpg    NoDamage\n",
       "19    test/Damage_404-Copy1.jpg      Damage\n",
       "20    test/Damage_405-Copy1.jpg    NoDamage\n",
       "21    test/Damage_410-Copy1.jpg      Damage\n",
       "22    test/Damage_415-Copy1.jpg    NoDamage\n",
       "23    test/Damage_420-Copy1.jpg      Damage\n",
       "24    test/Damage_999-Copy1.jpg      Damage\n",
       "25  test/NoDamage_106-Copy1.jpg    NoDamage\n",
       "26  test/NoDamage_116-Copy1.jpg    NoDamage\n",
       "27  test/NoDamage_154-Copy1.jpg      Damage\n",
       "28  test/NoDamage_162-Copy1.jpg    NoDamage\n",
       "29  test/NoDamage_169-Copy1.jpg      Damage\n",
       "30  test/NoDamage_176-Copy1.jpg    NoDamage\n",
       "31  test/NoDamage_182-Copy1.jpg      Damage\n",
       "32  test/NoDamage_191-Copy1.jpg      Damage\n",
       "33  test/NoDamage_197-Copy1.png    NoDamage\n",
       "34  test/NoDamage_205-Copy1.jpg    NoDamage\n",
       "35  test/NoDamage_208-Copy1.jpg      Damage\n",
       "36  test/NoDamage_210-Copy1.jpg    NoDamage\n",
       "37  test/NoDamage_220-Copy1.jpg    NoDamage\n",
       "38   test/NoDamage_24-Copy1.jpg    NoDamage\n",
       "39   test/NoDamage_31-Copy1.jpg    NoDamage\n",
       "40   test/NoDamage_36-Copy1.jpg    NoDamage\n",
       "41   test/NoDamage_41-Copy1.jpg      Damage\n",
       "42   test/NoDamage_45-Copy1.jpg    NoDamage\n",
       "43   test/NoDamage_51-Copy1.jpg      Damage\n",
       "44   test/NoDamage_60-Copy1.jpg    NoDamage\n",
       "45   test/NoDamage_65-Copy1.jpg    NoDamage\n",
       "46   test/NoDamage_70-Copy1.jpg    NoDamage\n",
       "47   test/NoDamage_77-Copy1.jpg    NoDamage\n",
       "48   test/NoDamage_84-Copy1.jpg      Damage\n",
       "49   test/NoDamage_90-Copy1.jpg    NoDamage\n",
       "50   test/NoDamage_98-Copy1.jpg    NoDamage\n",
       "51  test/NoDamage_998-Copy1.jpg    NoDamage"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "#results.to_csv(\"results.csv\",index=False \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-f68b2f6b57cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAccuracy on Test Data: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m print(\"\\nNumber of correctly identified imgaes: \",\n\u001b[1;32m      4\u001b[0m       accuracy_score(test_y, preds, normalize=False),\"\\n\")\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_features' is not defined"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(model.predict(test_features), axis=1)\n",
    "print(\"\\nAccuracy on Test Data: \", accuracy_score(test_y, preds))\n",
    "print(\"\\nNumber of correctly identified imgaes: \",\n",
    "      accuracy_score(test_y, preds, normalize=False),\"\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "heatmap_labels = ['NoDamage', 'Damage']\n",
    "\n",
    "sns.heatmap(confusion_matrix(test_y, preds, labels=range(0,2)), annot=True, annot_kws={\"size\": 10}, \n",
    "            fmt='g', cmap='OrRd', xticklabels=heatmap_labels, yticklabels=heatmap_labels)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobile_damage_estimator(image_path, model_transfer,vggModel):\n",
    "    \n",
    "        \n",
    "    print (\"Determining if damaged...\")\n",
    "    #urllib.urlretrieve(image_path, 'save.jpg') # or other way to upload image\n",
    "    img = load_img(image_path, target_size=(224, 224)) # this is a PIL image \n",
    "    x = img_to_array(img) # this is a Numpy array with shape (3, 256, 256)\n",
    "    #x = x.reshape((1,) + x.shape)/255 # this is a Numpy array with shape (1, 3, 256, 256)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    x = imagenet_utils.preprocess_input(x)\n",
    "    \n",
    "    features = vggModel.predict(x, batch_size=32)\n",
    "    \n",
    "    pred = model_transfer.predict(features)\n",
    "    pred_label = np.argmax(pred, axis=1)\n",
    "    \n",
    "    d = {0: 'NoDamage', 1: 'Damage'}\n",
    "    for key in d.keys():\n",
    "        if pred_label[0] == key:\n",
    "            print (\"Assessment: {} to Mobile\".format(d[key]))\n",
    "    print (\"Assessment complete.\")\n",
    "    view_images(image_path)\n",
    "    \n",
    "def view_images(img):\n",
    "    from IPython.display import Image, display, clear_output\n",
    "    #clear_output()\n",
    "    display(Image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_damage_estimator('./MobileImages/test1/Damage_999.jpg', model_transfer,model)\n",
    "mobile_damage_estimator('./MobileImages/test1/NoDamage_998.jpg', model_transfer,model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TestEnv] *",
   "language": "python",
   "name": "conda-env-TestEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
