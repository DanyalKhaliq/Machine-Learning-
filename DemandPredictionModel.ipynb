{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Prediction using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVR\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_pickle('./DemandDataFile', compression='infer')\n",
    "df_region = pd.read_pickle('./RegionDataFile', compression='infer')\n",
    "df_initial = pd.merge(df_initial, df_region, how='inner', right_on=['CITY_NAME'], left_on=['CITY'])\n",
    "df_initial = df_initial.drop(['CITY_NAME'], axis=1)\n",
    "\n",
    "df_initial = df_initial[~df_initial['PRODUCT_NAME'].str.contains(\"Small Flyers|Large Flyers|Meter Bubble Wrap|Bundle of 50 Boxes|Wrap\", na=False)]\n",
    "df_initial.rename(columns = {'ORDER_DATE':'DATE'},inplace = True)\n",
    "df_initial.sort_values('DATE',ascending=True, inplace = True)\n",
    "df_initial.DATE = pd.to_datetime(df_initial['DATE'])\n",
    "\n",
    "df_reviews = pd.read_csv('./ProductReviews.csv')\n",
    "df_initial = pd.merge(df_initial, df_reviews, how='left', right_on=['COD_SKU_CONFIG'], left_on=['SKU'])\n",
    "df_initial = df_initial.drop(['COD_SKU_CONFIG'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danyal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/danyal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "df_fraud = pd.read_csv('./FradulentOrders.csv',dtype={'ORDER_NR': str})\n",
    "\n",
    "df_initial = df_initial[~df_initial.COD_ORDER_NR.isin(df_fraud.ORDER_NR.tolist())]\n",
    "\n",
    "df_initial['WareHouse'] = 'Null'\n",
    "df_initial.loc[:,\"WareHouse\"][df_initial['REGION_NAME'].isin(['Sindh','Balochistan'])] = 'Karachi'\n",
    "df_initial.loc[:,\"WareHouse\"][~df_initial['REGION_NAME'].isin(['Sindh','Balochistan'])] = 'Lahore'\n",
    "#df_initial['WareHouse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isHoliday(x):\n",
    "    if x in df_hday18.Date.values:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hday18 = pd.read_csv('./Holidays2018.csv')\n",
    "df_hday18.Date = pd.to_datetime(df_hday18['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2683504, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_initial[df_initial.IsHoliday == 1].head()\n",
    "df_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['MedianPrice'] = df_initial.groupby('SKU')['UNIT_PRICE'].transform('median')\n",
    "df_initial['MedianPrice'] = pd.to_numeric(df_initial['MedianPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2683504, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial['CatConcat'] = df_initial[['PRODUCT_NAME','BRAND_NAME','CATEGORY_LEVEL_1', 'CATEGORY_LEVEL_2','CATEGORY_LEVEL_3','CATEGORY_LEVEL_4']].apply(lambda x: ' | '.join(x.str.strip()), axis=1)\n",
    "df_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shift(df,dateCol,groupCol):\n",
    "    df['group_no'] = df.groupby([groupCol]).ngroup()\n",
    "    tmp = df[[dateCol,'Quantity','group_no']].set_index(['group_no',dateCol])\\\n",
    "                                          .unstack('group_no')\\\n",
    "                                          .resample('D').asfreq()\n",
    "    tmp1 = tmp.shift(1).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D1')\n",
    "    tmp2 = tmp.shift(2).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D2')\n",
    "    tmp3 = tmp.shift(3).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D3')\n",
    "    tmp4 = tmp.shift(4).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D4')\n",
    "    tmp5 = tmp.shift(5).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D5')\n",
    "    \n",
    "    df = df.join(tmp1, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp2, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp3, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp4, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp5, on=[dateCol,'group_no'])\n",
    "    \n",
    "    df.drop(axis=1, columns=['group_no'], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_inf(x):\n",
    "    if x>0:\n",
    "        return np.log(x) \n",
    "    else:\n",
    "        return np.log(1) \n",
    "\n",
    "def is_bundle(x):\n",
    "    if 'Bundle' in x or 'Pack' in x or '+' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_Gender(x):\n",
    "    if 'Men' in x:\n",
    "        return 'MEN'\n",
    "    elif 'Woman' in x:\n",
    "        return 'WOMAN'\n",
    "    else:\n",
    "        return 'NEUTRAL'\n",
    "    \n",
    "def is_GroceryOrBaby(x):\n",
    "    if 'Grocer' in x or 'Baby' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def is_PrevWeekHoliday(x):\n",
    "    if len(tempHolidayWeek[tempHolidayWeek  == x].values) > 0 :\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def prepareDataFrame(wareHouse):\n",
    "    train_df = df_initial[['SKU','DATE','WareHouse','Quantity','MedianPrice','PRODUCT_NAME','CatConcat']][df_initial.WareHouse == wareHouse]\n",
    "    \n",
    "    \n",
    "    train_df['IsBundle'] = train_df['PRODUCT_NAME'].map(is_bundle)\n",
    "    train_df['ProductGender'] = train_df['CatConcat'].map(product_Gender)\n",
    "    train_df['IsGrocery'] = train_df['CatConcat'].map(is_GroceryOrBaby)\n",
    "    \n",
    "    #train_df = train_df[(train_df.SKU == 'HP770OT03D0JKNAFAMZ') | (train_df.SKU == 'SH069FA039PJONAFAMZ')]\n",
    "    train_df = train_df.groupby(by=['SKU','DATE','WareHouse','MedianPrice','IsBundle','IsGrocery','ProductGender','PRODUCT_NAME','CatConcat'], as_index=False)['Quantity'].sum()\n",
    "    train_df.sort_values('DATE',ascending=True, inplace = True)\n",
    "    train_df.DATE = pd.to_datetime(train_df['DATE'])\n",
    "    train_df = train_df.set_index('DATE')\n",
    "\n",
    "    \n",
    "    #Gettign the SKUs whcih were not demanded on the start date \n",
    "    startDate = '2017-12-01'\n",
    "    temp = train_df.reset_index().groupby('SKU').first()\n",
    "    temp.drop(temp[temp.DATE == startDate].index, inplace=True)\n",
    "\n",
    "    # replacing date to the Min Start date & Quantity Demand to None\n",
    "    temp['DATE'] = pd.to_datetime(startDate)\n",
    "    temp['Quantity'] = 0\n",
    "    if temp.index.name == 'SKU':\n",
    "        temp.reset_index(inplace = True)\n",
    "    \n",
    "    temp = temp.set_index('DATE')\n",
    "    \n",
    "    train_df = train_df.append(temp)\n",
    "    train_df.reset_index(inplace=True)\n",
    "    train_df['WEEKDAY'] = train_df['DATE'].apply(lambda x:calendar.day_name[x.weekday()])\n",
    "    train_df['MONTH'] = train_df['DATE'].apply(lambda x:calendar.month_abbr[x.month])\n",
    "    train_df['IsHoliday'] = [isHoliday(x) for x in train_df['DATE'].values]\n",
    "    \n",
    "    train_df['YEAR'] = train_df['DATE'].apply(lambda x:x.year)\n",
    "    train_df['YEAR'] = train_df['YEAR'].apply(str)\n",
    "    \n",
    "    train_df['WEEKNO'] = train_df['DATE'].dt.week\n",
    "    #train_df['WEEKNO'] = train_df['WEEKNO'].apply(str)\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    train_df = train_df.groupby(by=['SKU','YEAR','WEEKNO','WareHouse','MedianPrice','IsGrocery','IsBundle','ProductGender','PRODUCT_NAME','CatConcat'], as_index=False)['Quantity','IsHoliday'].sum()\n",
    "   \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(722498, 12)\n",
      "(1112549, 12)\n"
     ]
    }
   ],
   "source": [
    "tempKhi = prepareDataFrame('Karachi')\n",
    "tempKhi = tempKhi.sort_values(by=['SKU','YEAR', 'WEEKNO'], ascending=True)\n",
    "tempKhi['WEEKNO'] = tempKhi['WEEKNO'].apply(int)\n",
    "tempKhi.fillna(0, inplace=True)\n",
    "print(tempKhi.shape)\n",
    "#train_df = temp.copy()\n",
    "\n",
    "tempLhr = prepareDataFrame('Lahore')\n",
    "tempLhr = tempLhr.sort_values(by=['SKU','YEAR', 'WEEKNO'], ascending=True)\n",
    "tempLhr['WEEKNO'] = tempLhr['WEEKNO'].apply(int)\n",
    "tempLhr.fillna(0, inplace=True)\n",
    "print(tempLhr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempLhr['Last_Week_Sales'] = tempLhr.groupby(['SKU'])['Quantity'].shift(1)[(tempLhr.WEEKNO == tempLhr.WEEKNO.shift(1) + 1)]\n",
    "tempLhr['Last_Week_Diff'] = tempLhr.groupby(['SKU'])['Last_Week_Sales'].diff(1)[(tempLhr.WEEKNO == tempLhr.WEEKNO.shift(1) + 1)]\n",
    "#tempLhr[(tempLhr.SKU == '00301FA025DPKNAFAMZ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempKhi['Last_Week_Sales'] = tempKhi.groupby(['SKU'])['Quantity'].shift()[(tempKhi.WEEKNO == tempKhi.WEEKNO.shift() + 1)]\n",
    "tempKhi['Last_Week_Diff'] = tempKhi.groupby(['SKU'])['Last_Week_Sales'].diff(1)[(tempKhi.WEEKNO == tempKhi.WEEKNO.shift(1) + 1)]\n",
    "#tempKhi[(tempKhi.SKU == '00301FA025DPKNAFAMZ')]\n",
    "#train_df[train_df.SKU == '00301FA025DPKNAFAMZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([tempKhi, tempLhr])\n",
    "tempHolidayWeek = temp[temp.IsHoliday == 1]['WEEKNO'].unique()\n",
    "\n",
    "tempHolidayWeek = (pd.Series(tempHolidayWeek + 1))\n",
    "temp['PrevWeekHoliday'] = temp.WEEKNO.apply(lambda x : len(tempHolidayWeek[tempHolidayWeek  == x].values) > 0)\n",
    "\n",
    "#since we added 1 above so we are subtracting 2\n",
    "tempHolidayWeek = (pd.Series(tempHolidayWeek - 2))\n",
    "temp['NextWeekHoliday'] = temp.WEEKNO.apply(lambda x : len(tempHolidayWeek[tempHolidayWeek  == x].values) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>WEEKNO</th>\n",
       "      <th>WareHouse</th>\n",
       "      <th>MedianPrice</th>\n",
       "      <th>IsGrocery</th>\n",
       "      <th>IsBundle</th>\n",
       "      <th>ProductGender</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>CatConcat</th>\n",
       "      <th>...</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Last_Week_Sales</th>\n",
       "      <th>Last_Week_Diff</th>\n",
       "      <th>PrevWeekHoliday</th>\n",
       "      <th>NextWeekHoliday</th>\n",
       "      <th>Karachi</th>\n",
       "      <th>Lahore</th>\n",
       "      <th>MEN</th>\n",
       "      <th>NEUTRAL</th>\n",
       "      <th>WOMAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00301FA025DPKNAFAMZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>48</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEN</td>\n",
       "      <td>Unisex Style Baseball Cap - Black</td>\n",
       "      <td>Unisex Style Baseball Cap - Black | 0092 store...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00301FA025DPKNAFAMZ</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEN</td>\n",
       "      <td>Unisex Style Baseball Cap - Black</td>\n",
       "      <td>Unisex Style Baseball Cap - Black | 0092 store...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00301FA025DPKNAFAMZ</td>\n",
       "      <td>2018</td>\n",
       "      <td>19</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEN</td>\n",
       "      <td>Unisex Style Baseball Cap - Black</td>\n",
       "      <td>Unisex Style Baseball Cap - Black | 0092 store...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00301FA025DPKNAFAMZ</td>\n",
       "      <td>2018</td>\n",
       "      <td>21</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEN</td>\n",
       "      <td>Unisex Style Baseball Cap - Black</td>\n",
       "      <td>Unisex Style Baseball Cap - Black | 0092 store...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00301FA0QSN4YNAFAMZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>48</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>Blue Golden Tulip Brooch For Women</td>\n",
       "      <td>Blue Golden Tulip Brooch For Women | 0092 stor...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   SKU  YEAR  WEEKNO WareHouse  MedianPrice  IsGrocery  \\\n",
       "0  00301FA025DPKNAFAMZ  2017      48   Karachi        399.0          0   \n",
       "1  00301FA025DPKNAFAMZ  2018      18   Karachi        399.0          0   \n",
       "2  00301FA025DPKNAFAMZ  2018      19   Karachi        399.0          0   \n",
       "3  00301FA025DPKNAFAMZ  2018      21   Karachi        399.0          0   \n",
       "4  00301FA0QSN4YNAFAMZ  2017      48   Karachi        600.0          0   \n",
       "\n",
       "   IsBundle ProductGender                        PRODUCT_NAME  \\\n",
       "0         0           MEN   Unisex Style Baseball Cap - Black   \n",
       "1         0           MEN   Unisex Style Baseball Cap - Black   \n",
       "2         0           MEN   Unisex Style Baseball Cap - Black   \n",
       "3         0           MEN   Unisex Style Baseball Cap - Black   \n",
       "4         0       NEUTRAL  Blue Golden Tulip Brooch For Women   \n",
       "\n",
       "                                           CatConcat  ...    IsHoliday  \\\n",
       "0  Unisex Style Baseball Cap - Black | 0092 store...  ...            1   \n",
       "1  Unisex Style Baseball Cap - Black | 0092 store...  ...            0   \n",
       "2  Unisex Style Baseball Cap - Black | 0092 store...  ...            0   \n",
       "3  Unisex Style Baseball Cap - Black | 0092 store...  ...            0   \n",
       "4  Blue Golden Tulip Brooch For Women | 0092 stor...  ...            1   \n",
       "\n",
       "   Last_Week_Sales  Last_Week_Diff  PrevWeekHoliday  NextWeekHoliday  Karachi  \\\n",
       "0              0.0             0.0                0                0        1   \n",
       "1              0.0             0.0                0                0        1   \n",
       "2              1.0             0.0                1                0        1   \n",
       "3              0.0             0.0                0                0        1   \n",
       "4              0.0             0.0                0                0        1   \n",
       "\n",
       "   Lahore  MEN  NEUTRAL  WOMAN  \n",
       "0       0    1        0      0  \n",
       "1       0    1        0      0  \n",
       "2       0    1        0      0  \n",
       "3       0    1        0      0  \n",
       "4       0    0        1      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.fillna(0, inplace=True)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "#bins = np.arange(0,60,5) , use bins=bins in hist function below for smaller values\n",
    "train_df['Quantity'].hist(ax=ax, bottom=0.1)\n",
    "\n",
    "#formatter = FuncFormatter(log_10_product)\n",
    "ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[train_df['Quantity'] > 500].PRODUCT_NAME.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_initial.groupby(by=['DATE','SKU','CATEGORY_LEVEL_1'], as_index=False)['Quantity'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "g = sns.FacetGrid(test[test.Quantity < 1000], col=\"CATEGORY_LEVEL_1\")\n",
    "g = g.map(plt.hist, \"Quantity\", log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BenchMark Model (Predict Demand as Avergae of last N days demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = train_df[(train_df.DATE >= '2018-05-01') & (train_df.Quantity <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['PredictedDemand'] = np.int64((test_df.D1+test_df.D2+test_df.D3+test_df.D4+test_df.D5)/5)\n",
    "#test_df.loc[:,'PredictedDemand'] = test_df['PredictedDemand'].apply(lambda x : log_inf(x))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(\"MSE: \",mean_squared_error(test_df.Quantity, test_df.PredictedDemand),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error(test_df.Quantity, test_df.PredictedDemand))\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML model Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.drop(axis=1, columns=['Karachi','Lahore'], inplace = True)\n",
    "if not {'MEN', 'NEUTRAL','Karachi','Lahore'}.issubset(temp.columns):\n",
    "    dummyWareHouse = pd.get_dummies(temp['WareHouse']).astype(int)\n",
    "    dummyProductGender = pd.get_dummies(temp['ProductGender']).astype(int)\n",
    "    temp = pd.concat([temp,dummyWareHouse], axis = 1)\n",
    "    temp = pd.concat([temp,dummyProductGender], axis = 1)\n",
    "    temp.PrevWeekHoliday = temp.PrevWeekHoliday.astype(int)\n",
    "    temp.NextWeekHoliday = temp.NextWeekHoliday.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = ['WEEKNO','Lahore','IsHoliday','IsBundle','MEN','NEUTRAL','WOMAN','MedianPrice','PrevWeekHoliday','Last_Week_Sales','Last_Week_Diff','Quantity']\n",
    "testWeeks = [19,20,21,22]\n",
    "train_df = temp\n",
    "X = train_df[~train_df.WEEKNO.isin(testWeeks)][colList]\n",
    "#X.MedianPrice = X.MedianPrice.map(log_inf)\n",
    "#Y_orig = train_df[~train_df.WEEKNO.isin(testWeeks)][['Quantity']]\n",
    "#Y = Y_orig.Quantity.map(log_inf)\n",
    "Y = X.iloc[:,-1]\n",
    "X = X.iloc[:,0:X.shape[1]-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = train_df[train_df.WEEKNO.isin(testWeeks)][colList]\n",
    "#X_test.MedianPrice = X_test.MedianPrice.map(log_inf)\n",
    "#Y_test_orig = train_df[train_df.WEEKNO.isin(testWeeks)][['Quantity']]\n",
    "#Y_test = Y_test_orig.Quantity.map(log_inf)\n",
    "Y_test = X_test.iloc[:,-1]\n",
    "#X_test_SKUs = train_df[(train_df.DATE >= '2018-05-01') & (train_df.Quantity <= 200)][['SKU']]\n",
    "X_test = X_test.iloc[:,0:X_test.shape[1]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Decision Tree Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  500.78440176534644 RMSE:  22.378212657970394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regr = DecisionTreeRegressor(max_depth=8,min_samples_split=7,min_samples_leaf=7)\n",
    "regr.fit(X, Y)\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "import math\n",
    "print(\"MSE: \",mean_squared_error((Y_test), (y_pred)),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error((Y_test), (y_pred)))\n",
    "     )\n",
    "# print(\"MSE: \",mean_squared_error((np.exp(Y_test)), np.exp((y_pred))),\n",
    "#       \"RMSE: \",math.sqrt(mean_squared_error(np.exp((Y_test)), np.exp((y_pred))))\n",
    "#      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Actual Demand :  490434 \n",
      "Total Predicted Demand :  457393.0996375618\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>66</td>\n",
       "      <td>19.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>68</td>\n",
       "      <td>36.460879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>71</td>\n",
       "      <td>26.032882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27847</th>\n",
       "      <td>89</td>\n",
       "      <td>71.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27849</th>\n",
       "      <td>62</td>\n",
       "      <td>36.460879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44374</th>\n",
       "      <td>54</td>\n",
       "      <td>1.521114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48272</th>\n",
       "      <td>61</td>\n",
       "      <td>71.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48273</th>\n",
       "      <td>60</td>\n",
       "      <td>58.552058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51425</th>\n",
       "      <td>76</td>\n",
       "      <td>36.460879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51427</th>\n",
       "      <td>58</td>\n",
       "      <td>19.877159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54088</th>\n",
       "      <td>63</td>\n",
       "      <td>17.855611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55275</th>\n",
       "      <td>95</td>\n",
       "      <td>9.397721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55276</th>\n",
       "      <td>68</td>\n",
       "      <td>58.552058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94320</th>\n",
       "      <td>167</td>\n",
       "      <td>1.521114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94330</th>\n",
       "      <td>125</td>\n",
       "      <td>176.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94331</th>\n",
       "      <td>160</td>\n",
       "      <td>91.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94336</th>\n",
       "      <td>125</td>\n",
       "      <td>1.521114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94337</th>\n",
       "      <td>125</td>\n",
       "      <td>1.521114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130498</th>\n",
       "      <td>67</td>\n",
       "      <td>2.555192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145494</th>\n",
       "      <td>91</td>\n",
       "      <td>1.521114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145498</th>\n",
       "      <td>85</td>\n",
       "      <td>1.521114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145514</th>\n",
       "      <td>113</td>\n",
       "      <td>1.521114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148581</th>\n",
       "      <td>96</td>\n",
       "      <td>19.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157105</th>\n",
       "      <td>59</td>\n",
       "      <td>36.460879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157107</th>\n",
       "      <td>54</td>\n",
       "      <td>36.460879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual   Predicted\n",
       "1398        66   19.604167\n",
       "9106        68   36.460879\n",
       "21513       71   26.032882\n",
       "27847       89   71.500000\n",
       "27849       62   36.460879\n",
       "44374       54    1.521114\n",
       "48272       61   71.500000\n",
       "48273       60   58.552058\n",
       "51425       76   36.460879\n",
       "51427       58   19.877159\n",
       "54088       63   17.855611\n",
       "55275       95    9.397721\n",
       "55276       68   58.552058\n",
       "94320      167    1.521114\n",
       "94330      125  176.487179\n",
       "94331      160   91.750000\n",
       "94336      125    1.521114\n",
       "94337      125    1.521114\n",
       "130498      67    2.555192\n",
       "145494      91    1.521114\n",
       "145498      85    1.521114\n",
       "145514     113    1.521114\n",
       "148581      96   19.604167\n",
       "157105      59   36.460879\n",
       "157107      54   36.460879"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold = pd.DataFrame()\n",
    "# hold['Actual'] = np.exp(Y_test)\n",
    "# hold['Predicted'] = np.exp(y_pred)\n",
    "\n",
    "hold['Actual'] = Y_test\n",
    "hold['Predicted'] = y_pred\n",
    "\n",
    "print('Total Actual Demand : ',hold.Actual.sum(),'\\nTotal Predicted Demand : ',hold.Predicted.sum())\n",
    "\n",
    "hold[hold.Actual > 50][['Actual','Predicted']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def visualize_tree(tree, feature_names):\n",
    "    \"\"\"Create tree png using graphviz.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tree -- scikit-learn DecsisionTree.\n",
    "    feature_names -- list of feature names.\n",
    "    \"\"\"\n",
    "    with open(\"dt.dot\", 'w') as f:\n",
    "        export_graphviz(tree, out_file=f,\n",
    "                        feature_names=feature_names)\n",
    "\n",
    "    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\n",
    "    try:\n",
    "        subprocess.check_call(command)\n",
    "    except:\n",
    "        exit(\"Could not run dot, ie graphviz, to \"\n",
    "             \"produce visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['WeekDayNo','Lahore','IsBundle','MEN','NEUTRAL']\n",
    "visualize_tree(regr, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_list = list(set(X_test.SKU.unique())-set(X.SKU.unique()))\n",
    "len(main_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  493.6423750102816 RMSE:  22.218064159829083\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor  \n",
    "import scipy.stats as st\n",
    "\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(1, 20)\n",
    "\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(2, 20),\n",
    "    \"max_depth\": st.randint(2, 10),\n",
    "    \"learning_rate\": st.uniform(0.01, 0.1),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}\n",
    "\n",
    "xgbreg = XGBRegressor(params=params) \n",
    "\n",
    "xgbreg.fit(X, Y)\n",
    "y_pred = xgbreg.predict(X_test)\n",
    "\n",
    "import math\n",
    "print(\"MSE: \",mean_squared_error((Y_test), (y_pred)),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error((Y_test), (y_pred)))\n",
    "     )\n",
    "# print(\"MSE: \",mean_squared_error((np.exp(Y_test)), np.exp((y_pred))),\n",
    "#       \"RMSE: \",math.sqrt(mean_squared_error(np.exp((Y_test)), np.exp((y_pred))))\n",
    "#      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create a Linear Regressor   \n",
    "lin_regressor = LinearRegression()\n",
    "\n",
    "# pass the order of your polynomial here  \n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# convert to be used further to linear regression\n",
    "X_transform = poly.fit_transform(X)\n",
    "\n",
    "# fit this to Linear Regressor\n",
    "lin_regressor.fit(X_transform,Y.Quantity) \n",
    "\n",
    "# get the predictions\n",
    "y_pred = lin_regressor.predict(X_test)\n",
    "\n",
    "import math\n",
    "print(\"MSE: \",mean_squared_error((Y_test), (y_pred)),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error((Y_test), (y_pred)))\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_test\n",
    "temp['Pred'] = y_pred\n",
    "temp['Act'] = Y_test\n",
    "\n",
    "temp[temp.Act >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch For Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear',\n",
       "       params={'n_esti..._state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f72423bdb70>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f72445125c0>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f724462e828>, 'colsample_bytree...3c9ba8>, 'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f72443c9ba8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "gs = RandomizedSearchCV(xgbreg, params, n_jobs=1)  \n",
    "gs.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1509.2202431302985 RMSE:  38.84868393047953\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "import math\n",
    "print(\"MSE: \",mean_squared_error((Y_test), (y_pred)),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error((Y_test), (y_pred)))\n",
    "     )\n",
    "# print(\"MSE: \",mean_squared_error((np.exp(Y_test)), np.exp((y_pred))),\n",
    "#       \"RMSE: \",math.sqrt(mean_squared_error(np.exp((Y_test)), np.exp((y_pred))))\n",
    "#      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's l1: 2.35096\n",
      "[100]\tvalid_0's l1: 2.34144\n",
      "[150]\tvalid_0's l1: 2.35066\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's l1: 2.33982\n",
      "MSE:  1508.388165523654 RMSE:  38.837973241708355\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l1',\n",
    "    'num_threads': 4\n",
    "}\n",
    "MAX_ROUNDS = 200\n",
    "\n",
    "lgb_train = lgb.Dataset(X, Y)\n",
    "lgb_test = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    "\n",
    "gbm = lgb.train(\n",
    "       params, lgb_train, num_boost_round=MAX_ROUNDS,\n",
    "       valid_sets=lgb_test, early_stopping_rounds=50, verbose_eval=50\n",
    "   )\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "import math\n",
    "print(\"MSE: \",mean_squared_error((Y_test), (y_pred)),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error((Y_test), (y_pred)))\n",
    "     )\n",
    "# print(\"MSE: \",mean_squared_error((np.exp(Y_test)), np.exp((y_pred))),\n",
    "#       \"RMSE: \",math.sqrt(mean_squared_error(np.exp((Y_test)), np.exp((y_pred))))\n",
    "#      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
