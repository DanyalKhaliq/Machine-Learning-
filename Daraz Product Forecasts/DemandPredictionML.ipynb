{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Prediction using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_pickle('./DemandDataFile', compression='infer')\n",
    "df_region = pd.read_pickle('./RegionDataFile', compression='infer')\n",
    "df_initial = pd.merge(df_initial, df_region, how='inner', right_on=['CITY_NAME'], left_on=['CITY'])\n",
    "df_initial = df_initial.drop(['CITY_NAME'], axis=1)\n",
    "df_initial = df_initial[~df_initial['PRODUCT_NAME'].str.contains(\"Small Flyers|Large Flyers|Meter Bubble Wrap|Bundle of 50 Boxes\", na=False)]\n",
    "df_initial.rename(columns = {'ORDER_DATE':'DATE'},inplace = True)\n",
    "df_initial.sort_values('DATE',ascending=True, inplace = True)\n",
    "df_initial.DATE = pd.to_datetime(df_initial['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = pd.read_csv('./FradulentOrders.csv',dtype={'ORDER_NR': str})\n",
    "\n",
    "df_initial = df_initial[~df_initial.COD_ORDER_NR.isin(df_fraud.ORDER_NR.tolist())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danyal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/danyal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lahore     1713866\n",
       "Karachi     977428\n",
       "Name: WareHouse, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial['WareHouse'] = 'Null'\n",
    "df_initial.loc[:,\"WareHouse\"][df_initial['REGION_NAME'].isin(['Sindh','Balochistan'])] = 'Karachi'\n",
    "df_initial.loc[:,\"WareHouse\"][~df_initial['REGION_NAME'].isin(['Sindh','Balochistan'])] = 'Lahore'\n",
    "df_initial['WareHouse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['MedianPrice'] = df_initial.groupby('SKU')['UNIT_PRICE'].transform('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_ORDER_NR</th>\n",
       "      <th>SKU</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CATEGORY_LEVEL_1</th>\n",
       "      <th>CATEGORY_LEVEL_2</th>\n",
       "      <th>CATEGORY_LEVEL_3</th>\n",
       "      <th>CATEGORY_LEVEL_4</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>UNIT_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>PAYMENT_OPTION</th>\n",
       "      <th>CTV</th>\n",
       "      <th>Gender</th>\n",
       "      <th>CITY</th>\n",
       "      <th>Voucher</th>\n",
       "      <th>MV</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>REGION_NAME</th>\n",
       "      <th>WareHouse</th>\n",
       "      <th>MedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2865522</th>\n",
       "      <td>304859521</td>\n",
       "      <td>MA521HL1LKRQANAFAMZ</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>Home &amp; Living</td>\n",
       "      <td>Kitchen &amp; Dining</td>\n",
       "      <td>Kitchen Tools &amp; Accessories</td>\n",
       "      <td>Kitchen Accessories</td>\n",
       "      <td>Measuring Cups &amp; spoons - Black</td>\n",
       "      <td>MAK TECH</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>COD</td>\n",
       "      <td>1260971</td>\n",
       "      <td>male</td>\n",
       "      <td>Khairpur</td>\n",
       "      <td>29.9</td>\n",
       "      <td>150.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sindh</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974837</th>\n",
       "      <td>309169521</td>\n",
       "      <td>IT313OT158UD8NAFAMZ</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>Grocer's Shop</td>\n",
       "      <td>Canned &amp; Packaged Foods</td>\n",
       "      <td>Canned &amp; Jarred Food</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Extra Virgin Olive Oil - 250 ml</td>\n",
       "      <td>ITALIA</td>\n",
       "      <td>295.0</td>\n",
       "      <td>...</td>\n",
       "      <td>COD</td>\n",
       "      <td>883217</td>\n",
       "      <td>male</td>\n",
       "      <td>Khanpur mahar</td>\n",
       "      <td>106.2</td>\n",
       "      <td>778.8</td>\n",
       "      <td>3</td>\n",
       "      <td>Sindh</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236288</th>\n",
       "      <td>309141521</td>\n",
       "      <td>SH402EL0Z34CQNAFAMZ</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>Phones &amp; Tablets</td>\n",
       "      <td>Phone &amp; Tablet Accessories</td>\n",
       "      <td>Cases &amp; Covers</td>\n",
       "      <td>Android Phones</td>\n",
       "      <td>360 cover For Xiaomi Mi A1 - Black+Red</td>\n",
       "      <td>Shippers</td>\n",
       "      <td>699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>COD</td>\n",
       "      <td>1241380</td>\n",
       "      <td>male</td>\n",
       "      <td>Peshawar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>699.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Khyber Pakhtunkhwa</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571026</th>\n",
       "      <td>303341721</td>\n",
       "      <td>SA609OT148CBONAFAMZ</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>Computing &amp; Gaming</td>\n",
       "      <td>Computing</td>\n",
       "      <td>Storage</td>\n",
       "      <td>USB/Flash Drives</td>\n",
       "      <td>Steel Body USB Drive - 32GB</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>COD</td>\n",
       "      <td>472261</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Nowshera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Khyber Pakhtunkhwa</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>1135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860063</th>\n",
       "      <td>306815721</td>\n",
       "      <td>PR960HB0ZSCGENAFAMZ</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>Beauty &amp; Health</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Hair Removal Tools</td>\n",
       "      <td>Waxes</td>\n",
       "      <td>Buy Pro Wax Warmer &amp; Get 100gm Wax Beans + Wax...</td>\n",
       "      <td>PRO WAX 100</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>COD</td>\n",
       "      <td>1259830</td>\n",
       "      <td>female</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        COD_ORDER_NR                  SKU       DATE    CATEGORY_LEVEL_1  \\\n",
       "2865522    304859521  MA521HL1LKRQANAFAMZ 2017-12-01       Home & Living   \n",
       "1974837    309169521  IT313OT158UD8NAFAMZ 2017-12-01       Grocer's Shop   \n",
       "1236288    309141521  SH402EL0Z34CQNAFAMZ 2017-12-01    Phones & Tablets   \n",
       "2571026    303341721  SA609OT148CBONAFAMZ 2017-12-01  Computing & Gaming   \n",
       "860063     306815721  PR960HB0ZSCGENAFAMZ 2017-12-01     Beauty & Health   \n",
       "\n",
       "                   CATEGORY_LEVEL_2             CATEGORY_LEVEL_3  \\\n",
       "2865522            Kitchen & Dining  Kitchen Tools & Accessories   \n",
       "1974837     Canned & Packaged Foods         Canned & Jarred Food   \n",
       "1236288  Phone & Tablet Accessories               Cases & Covers   \n",
       "2571026                   Computing                      Storage   \n",
       "860063                Personal Care           Hair Removal Tools   \n",
       "\n",
       "            CATEGORY_LEVEL_4  \\\n",
       "2865522  Kitchen Accessories   \n",
       "1974837                  N/A   \n",
       "1236288       Android Phones   \n",
       "2571026     USB/Flash Drives   \n",
       "860063                 Waxes   \n",
       "\n",
       "                                              PRODUCT_NAME   BRAND_NAME  \\\n",
       "2865522                    Measuring Cups & spoons - Black     MAK TECH   \n",
       "1974837                    Extra Virgin Olive Oil - 250 ml       ITALIA   \n",
       "1236288             360 cover For Xiaomi Mi A1 - Black+Red     Shippers   \n",
       "2571026                        Steel Body USB Drive - 32GB      Samsung   \n",
       "860063   Buy Pro Wax Warmer & Get 100gm Wax Beans + Wax...  PRO WAX 100   \n",
       "\n",
       "         UNIT_PRICE     ...      PAYMENT_OPTION      CTV  Gender  \\\n",
       "2865522       180.0     ...                 COD  1260971    male   \n",
       "1974837       295.0     ...                 COD   883217    male   \n",
       "1236288       699.0     ...                 COD  1241380    male   \n",
       "2571026      1135.0     ...                 COD   472261     N/A   \n",
       "860063       1298.0     ...                 COD  1259830  female   \n",
       "\n",
       "                  CITY  Voucher      MV Quantity         REGION_NAME  \\\n",
       "2865522       Khairpur     29.9   150.1        1               Sindh   \n",
       "1974837  Khanpur mahar    106.2   778.8        3               Sindh   \n",
       "1236288       Peshawar      NaN   699.0        1  Khyber Pakhtunkhwa   \n",
       "2571026       Nowshera      NaN  1135.0        1  Khyber Pakhtunkhwa   \n",
       "860063          Lahore      NaN  1298.0        1              Punjab   \n",
       "\n",
       "         WareHouse  MedianPrice  \n",
       "2865522    Karachi        180.0  \n",
       "1974837    Karachi        335.0  \n",
       "1236288     Lahore        699.0  \n",
       "2571026     Lahore       1135.0  \n",
       "860063      Lahore       1298.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shift(df,dateCol,groupCol):\n",
    "    df['group_no'] = df.groupby([groupCol]).ngroup()\n",
    "    tmp = df[[dateCol,'Quantity','group_no']].set_index(['group_no',dateCol])\\\n",
    "                                          .unstack('group_no')\\\n",
    "                                          .resample('D').asfreq()\n",
    "    tmp1 = tmp.shift(1).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D1')\n",
    "    tmp2 = tmp.shift(2).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D2')\n",
    "    tmp3 = tmp.shift(3).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D3')\n",
    "    tmp4 = tmp.shift(4).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D4')\n",
    "    tmp5 = tmp.shift(5).fillna(0).astype(int).stack('group_no')['Quantity'].rename('D5')\n",
    "    \n",
    "    df = df.join(tmp1, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp2, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp3, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp4, on=[dateCol,'group_no'])\n",
    "    df = df.join(tmp5, on=[dateCol,'group_no'])\n",
    "    \n",
    "    df.drop(axis=1, columns=['group_no'], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_inf(x):\n",
    "    if x>0:\n",
    "        return np.log(x) \n",
    "    else:\n",
    "        return np.log(1) \n",
    "\n",
    "def is_bundle(x):\n",
    "    if 'Bundle' in x or 'Pack' in x or '+' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401920, 23)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_initial[df_initial['PRODUCT_NAME'].map(is_bundle) == 1]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataFrame(wareHouse):\n",
    "    train_df = df_initial[['SKU','DATE','WareHouse','Quantity','MedianPrice','PRODUCT_NAME']][df_initial.WareHouse == wareHouse]\n",
    "    \n",
    "    train_df['IsBundle'] = train_df['PRODUCT_NAME'].map(is_bundle)\n",
    "    #train_df = train_df[(train_df.SKU == 'HP770OT03D0JKNAFAMZ') | (train_df.SKU == 'SH069FA039PJONAFAMZ')]\n",
    "    train_df = train_df.groupby(by=['SKU','DATE','WareHouse','MedianPrice','IsBundle'], as_index=False)['Quantity'].sum()\n",
    "    train_df.sort_values('DATE',ascending=True, inplace = True)\n",
    "    train_df.DATE = pd.to_datetime(train_df['DATE'])\n",
    "    train_df = train_df.set_index('DATE')\n",
    "\n",
    "    train_df.head()\n",
    "\n",
    "    #Gettign the SKUs whcih were not demanded on the start date \n",
    "    startDate = '2017-12-01'\n",
    "    temp = train_df.reset_index().groupby('SKU').first()\n",
    "    temp.drop(temp[temp.DATE == startDate].index, inplace=True)\n",
    "\n",
    "    # replacing date to the Min Start date & Quantity Demand to None\n",
    "    temp['DATE'] = pd.to_datetime(startDate)\n",
    "    temp['Quantity'] = 0\n",
    "    if temp.index.name == 'SKU':\n",
    "        temp.reset_index(inplace = True)\n",
    "    temp\n",
    "    temp = temp.set_index('DATE')\n",
    "    temp\n",
    "    train_df = train_df.append(temp)\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = prepareDataFrame('Karachi')\n",
    "temp.reset_index(inplace=True)\n",
    "train_df = compute_shift(temp.copy(),'DATE','SKU')\n",
    "\n",
    "temp = prepareDataFrame('Lahore')\n",
    "temp.reset_index(inplace=True)\n",
    "temp = compute_shift(temp.copy(),'DATE','SKU')\n",
    "train_df = train_df.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(0, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BenchMark Model (Predict Demand as Avergae of last N days demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = train_df[(train_df.DATE >= '2018-05-01') & (train_df.Quantity <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danyal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SKU</th>\n",
       "      <th>WareHouse</th>\n",
       "      <th>MedianPrice</th>\n",
       "      <th>IsBundle</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>PredictedDemand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551000</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>MO240HB10XKV0NAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551001</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>DA290FAGDTIPNAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>624.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551002</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>DM362EL08S8XINAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551003</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>IM505FA01BH2YNAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551004</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>RO070HL0GDBF0NAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE                  SKU WareHouse  MedianPrice  IsBundle  \\\n",
       "551000 2018-05-01  MO240HB10XKV0NAFAMZ   Karachi         95.0         1   \n",
       "551001 2018-05-01   DA290FAGDTIPNAFAMZ   Karachi        624.0         1   \n",
       "551002 2018-05-01  DM362EL08S8XINAFAMZ   Karachi        249.0         0   \n",
       "551003 2018-05-01  IM505FA01BH2YNAFAMZ   Karachi        300.0         0   \n",
       "551004 2018-05-01  RO070HL0GDBF0NAFAMZ   Karachi       1040.0         0   \n",
       "\n",
       "        Quantity   D1   D2   D3   D4   D5  PredictedDemand  \n",
       "551000         1  0.0  0.0  0.0  0.0  0.0                0  \n",
       "551001         1  0.0  0.0  0.0  0.0  0.0                0  \n",
       "551002         1  0.0  0.0  0.0  1.0  0.0                0  \n",
       "551003         1  0.0  0.0  0.0  0.0  0.0                0  \n",
       "551004         2  0.0  0.0  0.0  0.0  0.0                0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['PredictedDemand'] = np.int64((test_df.D1+test_df.D2+test_df.D3+test_df.D4+test_df.D5)/5)\n",
    "#test_df.loc[:,'PredictedDemand'] = test_df['PredictedDemand'].apply(lambda x : log_inf(x))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  21.006301364908193 RMSE:  4.583263178665196\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(\"MSE: \",mean_squared_error(test_df.Quantity, test_df.PredictedDemand),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error(test_df.Quantity, test_df.PredictedDemand))\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML model Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.drop(axis=1, columns=['Karachi','Lahore'], inplace = True)\n",
    "dummyWareHouse = pd.get_dummies(train_df['WareHouse'])\n",
    "dummyWareHouse\n",
    "\n",
    "train_df = pd.concat([train_df,dummyWareHouse], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "weekNumber = list(map((lambda x: x.isocalendar()[1]), train_df.DATE.dt.date)) \n",
    "train_df['WeekNo'] = weekNumber\n",
    "train_df['WeekDayNo'] = train_df.DATE.dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Train Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SKU</th>\n",
       "      <th>WareHouse</th>\n",
       "      <th>MedianPrice</th>\n",
       "      <th>IsBundle</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>Karachi</th>\n",
       "      <th>Lahore</th>\n",
       "      <th>WeekNo</th>\n",
       "      <th>WeekDayNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>AU697EL0O2TR8NAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>299.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>AL493FA1GB66UNAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>PA163FA1FDXFINAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>DE795EL08CH9ENAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>GR678EL1DZ76SNAFAMZ</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>59590.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE                  SKU WareHouse  MedianPrice  IsBundle  Quantity  \\\n",
       "0 2017-12-01  AU697EL0O2TR8NAFAMZ   Karachi        299.0         0         1   \n",
       "1 2017-12-01  AL493FA1GB66UNAFAMZ   Karachi       1800.0         0         1   \n",
       "2 2017-12-01  PA163FA1FDXFINAFAMZ   Karachi       1099.0         1         1   \n",
       "3 2017-12-01  DE795EL08CH9ENAFAMZ   Karachi        350.0         0         1   \n",
       "4 2017-12-01  GR678EL1DZ76SNAFAMZ   Karachi      59590.0         0         1   \n",
       "\n",
       "    D1   D2   D3   D4   D5  Karachi  Lahore  WeekNo  WeekDayNo  \n",
       "0  0.0  0.0  0.0  0.0  0.0        1       0      48          4  \n",
       "1  0.0  0.0  0.0  0.0  0.0        1       0      48          4  \n",
       "2  0.0  0.0  0.0  0.0  0.0        1       0      48          4  \n",
       "3  0.0  0.0  0.0  0.0  0.0        1       0      48          4  \n",
       "4  0.0  0.0  0.0  0.0  0.0        1       0      48          4  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[(train_df.DATE < '2018-05-01') & (train_df.Quantity <= 100)][['D1','D2','MedianPrice','WeekDayNo','Lahore','IsBundle']]\n",
    "X.MedianPrice = X.MedianPrice.map(log_inf)\n",
    "Y_orig = train_df[(train_df.DATE < '2018-05-01') & (train_df.Quantity <= 100)][['Quantity']]\n",
    "#Y = Y_orig.Quantity.map(log_inf)\n",
    "Y = Y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = train_df[(train_df.DATE >= '2018-05-01') & (train_df.Quantity <= 100)][['D1','D2','MedianPrice','WeekDayNo','Lahore','IsBundle']]\n",
    "X_test.MedianPrice = X_test.MedianPrice.map(log_inf)\n",
    "Y_test_orig = train_df[(train_df.DATE >= '2018-05-01') & (train_df.Quantity <= 100)][['Quantity']]\n",
    "#Y_test = Y_test_orig.Quantity.map(log_inf)\n",
    "Y_test = Y_test_orig\n",
    "X_test_SKUs = train_df[(train_df.DATE >= '2018-05-01') & (train_df.Quantity <= 100)][['SKU']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Decision Tree Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  9.34746804573288 RMSE:  3.0573629234575472\n"
     ]
    }
   ],
   "source": [
    "Y_test.shape\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regr = DecisionTreeRegressor(max_depth=7,min_samples_split=3,min_samples_leaf=5)\n",
    "regr.fit(X, Y)\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "import math\n",
    "print(\"MSE: \",mean_squared_error((Y_test), (y_pred)),\n",
    "      \"RMSE: \",math.sqrt(mean_squared_error((Y_test), (y_pred)))\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Actual Demand :  676646 \n",
      "Total Predicted Demand :  630510.6903750747\n"
     ]
    }
   ],
   "source": [
    "X_test['Actual'] = Y_test\n",
    "X_test['Predicted'] = y_pred\n",
    "#X_test['Actual'] = X_test['Actual'].map(np.exp)\n",
    "#X_test['Predicted'] = X_test['Predicted'].map(np.exp)\n",
    "#X_test[X_test.Actual > 5].head(100)\n",
    "#X.MedianPrice.describe()\n",
    "print('Total Actual Demand : ',X_test.Actual.sum(),'\\nTotal Predicted Demand : ',X_test.Predicted.sum())\n",
    "\n",
    "X_test_SKUs = train_df[(train_df.DATE >= '2018-05-01') & (train_df.Quantity <= 100)][['SKU']]\n",
    "X_test['SKU'] = X_test_SKUs\n",
    "\n",
    "X_train_SKUs = train_df[(train_df.DATE < '2018-05-01') & (train_df.Quantity <= 100)][['SKU']]\n",
    "X['SKU'] = X_train_SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def visualize_tree(tree, feature_names):\n",
    "    \"\"\"Create tree png using graphviz.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tree -- scikit-learn DecsisionTree.\n",
    "    feature_names -- list of feature names.\n",
    "    \"\"\"\n",
    "    with open(\"dt.dot\", 'w') as f:\n",
    "        export_graphviz(tree, out_file=f,\n",
    "                        feature_names=feature_names)\n",
    "\n",
    "    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\n",
    "    try:\n",
    "        subprocess.check_call(command)\n",
    "    except:\n",
    "        exit(\"Could not run dot, ie graphviz, to \"\n",
    "             \"produce visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['D1','D2','MedianPrice','WeekDayNo','Lahore','IsBundle']\n",
    "visualize_tree(regr, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "main_list = list(set(X_test.SKU.unique())-set(X.SKU.unique()))\n",
    "len(main_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch For Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_leaf': 10, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'max_depth': range(4,8,1),'min_samples_leaf':[1, 2, 4, 6, 8, 10]\n",
    "             ,'min_samples_split' : [2,4,6,8,10,12,14]} \n",
    "clf_tree = DecisionTreeRegressor() \n",
    "\n",
    "clf = GridSearchCV(clf_tree,parameters)\n",
    "clf.fit(X,Y)    \n",
    "clf.best_params_\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = clf.best_estimator_\n",
    "regr.fit(X, Y)\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
