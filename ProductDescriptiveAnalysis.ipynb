{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyodbc\n",
    "#conn = pyodbc.connect(\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={0}; database={1};UID={2};PWD={3}\".format('10.20.2.110,1433','AIG_DARAZ_PK_DW','daraz-tools','JfF7ziSCNk5jPxd'))\n",
    "#cursor = conn.cursor()\n",
    "\n",
    "#query = open('SqlForDailyDemandData.sql', 'r')\n",
    "#dataFrame_initial = pd.read_sql_query(query.read(), conn)\n",
    "#dataFrame_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFrame_initial.to_pickle('./dataFile',compression='infer', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_pickle('./dataFile', compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_initial.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = open('ProductVisibility.sql', 'r')\n",
    "#df_prodVisible = pd.read_sql_query(query.read(), conn)\n",
    "#df_prodVisible.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prodVisible.to_pickle('./productVisibilityDataFile',compression='infer', protocol=4)\n",
    "df_prodVisible = pd.read_pickle('./productVisibilityDataFile', compression='infer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prodVisible[df_prodVisible.DD_COD_SKU_CONFIG == '10259FA03RQUYNAFAMZ']['2018-02-10'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['date'] = pd.to_datetime(df_initial['date'])\n",
    "df_initial.sort_values(by='date').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_initial['DSC_PRODUCT_WEIGHT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# df_initial['DSC_PRODUCT_WEIGHT'] = df_initial['DSC_PRODUCT_WEIGHT'].apply(lambda x : re.sub(r'#', r'0', str(x)))\n",
    "# df_initial['DSC_PRODUCT_WEIGHT'] = df_initial['DSC_PRODUCT_WEIGHT'].apply(lambda x : re.sub(r'[a-zA-Z]', '', str(x)))\n",
    "# df_initial['DSC_PRODUCT_WEIGHT'] = df_initial['DSC_PRODUCT_WEIGHT'].apply(lambda x : re.sub(r'([.])\\1+', r'\\1', str(x)))\n",
    "# df_initial['DSC_PRODUCT_WEIGHT'] = df_initial['DSC_PRODUCT_WEIGHT'].apply(lambda x : re.sub(r'/', r'', str(x)))\n",
    "# df_initial['DSC_PRODUCT_WEIGHT'] = df_initial['DSC_PRODUCT_WEIGHT'].apply(lambda x : re.sub(r'[!]', '0', str(x)))\n",
    "# df_initial['DSC_PRODUCT_WEIGHT'] = pd.to_numeric(df_initial['DSC_PRODUCT_WEIGHT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_initial.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_initial[df_initial.DSC_PRODUCT_WEIGHT == df_initial['DSC_PRODUCT_WEIGHT'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['CatConcat'] = df_initial[['DSC_CATEGORY_NAME_LEVEL_1', 'DSC_CATEGORY_NAME_LEVEL_2','DSC_CATEGORY_NAME_LEVEL_3','DSC_CATEGORY_NAME_LEVEL_4']].apply(lambda x: ' '.join(x.str.strip()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_initial[df_initial.CatConcat == \"Grocer's Shop Cooking Essentials Rice, Flours, Pulses & Grains Rice\"]['DSC_PRODUCT_NAME'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_initial[df_initial.DSC_PRODUCT_NAME == 'Super Kernel Basmati Rice']['COD_SKU_CONFIG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_initial[(df_initial.DSC_PRODUCT_NAME == 'Super Kernel Basmati Rice') &\n",
    "#            (df_initial.DSC_PRODUCT_BRAND_NAME_EN == 'Xidmat')]['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newDf = df_initial[(df_initial.COD_SKU_CONFIG == 'RE775OT1GWF5GNAFAMZ')]['date'].to_frame()\n",
    "\n",
    "# newDf['CummulativeQuantity'] = df_initial[(df_initial.COD_SKU_CONFIG == 'RE775OT1GWF5GNAFAMZ')]['Valid Total'].cumsum()\n",
    "\n",
    "# newDf['DemandPercent'] = (newDf['CummulativeQuantity']/newDf['CummulativeQuantity'].iloc[-1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_initial[(df_initial.COD_SKU_CONFIG == SKUid)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newDf[40:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,7))\n",
    "# plt.plot(newDf.date, newDf.DemandPercent)\n",
    "# plt.ylabel('Percentage Demand', fontsize=12)\n",
    "# plt.xlabel('Date', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prodVisible = df_prodVisible.fillna(0)\n",
    "\n",
    "df_prodVisible = df_prodVisible.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prodVisible.columns = df_prodVisible.iloc[0]\n",
    "\n",
    "df_prodVisible = df_prodVisible.reindex(df_prodVisible.index.drop('DD_COD_SKU_CONFIG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prodVisible['2018-03-04':'2018-03-06'][['00301FA0IW7BMNAFAMZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_runs(a):\n",
    "    # Create an array that is 1 where a is 0, and pad each end with an extra 0.\n",
    "    iszero = np.concatenate(([0], np.equal(a, 0).view(np.int8), [0]))\n",
    "    absdiff = np.abs(np.diff(iszero))\n",
    "    # Runs start and end where absdiff is 1.\n",
    "    ranges = np.where(absdiff == 1)[0].reshape(-1, 2)\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOfflineData(offlineRaw,SKU_name):\n",
    "    dataFrame = pd.DataFrame()\n",
    "    for ind, column in enumerate(offlineRaw.columns):\n",
    "        runs = zero_runs(offlineRaw.iloc[:,ind])\n",
    "        tuples = zip(offlineRaw.iloc[runs[:,0],0].index, runs[:,1] - runs[:,0])\n",
    "        tempDf = {}\n",
    "        cols = ['OfflineDate','OfflineDays']\n",
    "        tuples = list(tuples)\n",
    "        tempDf = pd.DataFrame.from_records(tuples,columns = cols)\n",
    "        tempDf['SKU'] = column\n",
    "        dataFrame = dataFrame.append(tempDf)\n",
    "    return dataFrame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formattedDf = getOfflineData(df_prodVisible,df_prodVisible.columns.values[0])\n",
    "#formattedDf.to_pickle('./OfflineFormattedData',compression='infer', protocol=4)\n",
    "formattedDf = pd.read_pickle('./OfflineFormattedData', compression='infer')\n",
    "#formattedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample SKUs 00301FA0IW7BMNAFAMZ, 00301FA1IM7MANAFAMZ, 10259FA0074AYNAFAMZ\n",
    "#formattedDf['OfflineDate'] = pd.to_datetime(formattedDf['OfflineDate'])\n",
    "#df_initial.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline Product Similarity Match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKUid = '10259FA00UP2INAFAMZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PeriodStartDate = '2018-03-07'\n",
    "categoryName = df_initial[df_initial.COD_SKU_CONFIG == SKUid]['CatConcat'].unique()\n",
    "print(\"Concatenated Category Name : \", categoryName)\n",
    "productame = df_initial[df_initial.COD_SKU_CONFIG == SKUid]['DSC_PRODUCT_NAME'].unique()\n",
    "print(\"Product Name : \",productame)\n",
    "brandName = df_initial[df_initial.COD_SKU_CONFIG == SKUid]['DSC_PRODUCT_BRAND_NAME_EN'].unique()\n",
    "print(\"Brand : \" ,brandName)\n",
    "offlineStartDate = formattedDf[formattedDf.SKU == SKUid].iloc[3:4,0].values[0]\n",
    "print(\"Offline Start Date : \", offlineStartDate)\n",
    "\n",
    "offlineDays = formattedDf[formattedDf.SKU == SKUid].iloc[3:4,1].values[0]\n",
    "print(\"Stayed offline for # of Days : \", offlineDays)\n",
    "\n",
    "relevantSkuList = df_initial[(df_initial.CatConcat == categoryName[0]) & (df_initial.COD_SKU_CONFIG != SKUid)]['COD_SKU_CONFIG'].unique()\n",
    "#print('SKUs which have been sold during this period from this relevent category cluster ',len(relevantSkuList))\n",
    "\n",
    "#print('No of records in this Category, whose demand data we have in our date range of 5 months:',len(df_initial[(df_initial.CatConcat == categoryName[0]) & (df_initial.COD_SKU_CONFIG != '00301FA0IW7BMNAFAMZ')].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prodVisible[np.intersect1d(df_prodVisible.columns, list(relevantSkuList))].head()\n",
    "#df_prodVisible[df_prodVisible.columns.intersection(list(relevantSkuList))].head()\n",
    "\n",
    "formattedDf[formattedDf.SKU == SKUid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "releventSKUdataFrame = df_prodVisible[(datetime.strptime(PeriodStartDate, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")) : (datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1)).strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "releventSKUdataFrame = releventSKUdataFrame[releventSKUdataFrame.columns.intersection(list(relevantSkuList))].apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "releventSKUdataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findOnlineRelatedSKUs = releventSKUdataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findOnlineRelatedSKUs = findOnlineRelatedSKUs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if findOnlineRelatedSKUs.shape[1] == 2:\n",
    "     findOnlineRelatedSKUs.columns = ['Off', 'On']\n",
    "else:\n",
    "     findOnlineRelatedSKUs.columns = ['On']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findOnlineRelatedSKUs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get SKUs from the smilar valid SKU list which were OnLine atleast\n",
    "similarSKU4DC = findOnlineRelatedSKUs[findOnlineRelatedSKUs[\"On\"] > 0].index\n",
    "len(similarSKU4DC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demandCurveDf = df_initial[df_initial.COD_SKU_CONFIG.isin(similarSKU4DC)]\n",
    "demandCurveDf = demandCurveDf[(demandCurveDf.date >= datetime.strptime(PeriodStartDate, \"%Y-%m-%d\")) \n",
    "             & (demandCurveDf.date <= datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1))]\n",
    "#demandCurveDf = demandCurveDf['date'].to_frame()\n",
    "demandCurveDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if demandCurveDf.shape[0] > 0:\n",
    "    temp = pd.DataFrame(demandCurveDf.groupby(['date'])['Valid Total'].mean()).reset_index()\n",
    "    demandCurveDf = temp['date'].to_frame()\n",
    "    demandCurveDf['CummulativeQuantity'] = temp['Valid Total'].cumsum().round(1)\n",
    "    demandCurveDf['DemandPercent'] = (demandCurveDf['CummulativeQuantity']/demandCurveDf['CummulativeQuantity'].iloc[-1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demandCurveDf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_initial[df_initial.COD_SKU_CONFIG == SKUid]\n",
    "temp = temp[(temp.date >= datetime.strptime(PeriodStartDate, \"%Y-%m-%d\")) \n",
    "                     & (temp.date <= datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1))]\n",
    "\n",
    "if temp['COD_SKU_CONFIG'].count() > 0:\n",
    "    onlineDemand = 1\n",
    "    demandCurveDf4Offline = temp['date'].to_frame()\n",
    "    demandCurveDf4Offline['CummulativeQuantity'] = temp[(temp.COD_SKU_CONFIG == SKUid)]['Valid Total'].cumsum()\n",
    "    demandCurveDf4Offline['DemandPercent'] = (demandCurveDf4Offline['CummulativeQuantity']/demandCurveDf4Offline['CummulativeQuantity'].iloc[-1])*100\n",
    "    print(demandCurveDf4Offline)\n",
    "    #print(\"Recorded demand during Online period : \",temp['COD_SKU_CONFIG'].count())\n",
    "else:\n",
    "    onlineDemand = 0\n",
    "    print(\"No Demand Recorded during Online period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if onlineDemand > 0:\n",
    "    if (datetime.strptime(offlineStartDate, \"%Y-%m-%d\") > demandCurveDf4Offline[demandCurveDf4Offline.DemandPercent == 100]['date']).values[0]:\n",
    "        dateOfOFFLine = offlineStartDate\n",
    "    else:\n",
    "        dateOfOFFLine = demandCurveDf4Offline[demandCurveDf4Offline.DemandPercent == 100]['date'].values[0]\n",
    "    if int(offlineDays) > 1:\n",
    "        DemandPercentWhenSoldOut = demandCurveDf[demandCurveDf.date <= dateOfOFFLine].tail(1)['DemandPercent']/100\n",
    "    else:\n",
    "        DemandPercentWhenSoldOut = demandCurveDf[demandCurveDf.date <= dateOfOFFLine][-2:-1]['DemandPercent']/100\n",
    "    if DemandPercentWhenSoldOut.count() == 0:\n",
    "        print(\"Estiamted Lost Sales (Category SO) :\",DemandPercentWhenSoldOut.count())\n",
    "    else:\n",
    "        CummulativeQuantityWhenSoldOut = demandCurveDf4Offline[demandCurveDf4Offline.DemandPercent == 100]['CummulativeQuantity']\n",
    "        print(\"Cummulative Quantity When Sold Out:\",CummulativeQuantityWhenSoldOut.values[0])\n",
    "        print(\"Demand Percent of Category when the product went offline \",DemandPercentWhenSoldOut.values[0])\n",
    "        EstiamtedLostSales = CummulativeQuantityWhenSoldOut/DemandPercentWhenSoldOut.values[0]\n",
    "        print(\"Estiamted Lost Sales :\",(EstiamtedLostSales.values[0] - CummulativeQuantityWhenSoldOut).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "markers_on = [DemandPercentWhenSoldOut.index[0]]\n",
    "plt.plot(demandCurveDf.date, demandCurveDf.DemandPercent,'-bX',markevery=markers_on)\n",
    "\n",
    "for a,b in zip(demandCurveDf.date, demandCurveDf.DemandPercent): \n",
    "    if( b == DemandPercentWhenSoldOut.values[0] * 100):\n",
    "        plt.text(a, b, \"Category Demand % : \" + str(b) + \"  \\nDate : \" + str(a))\n",
    "        \n",
    "plt.ylabel('Percentage Demand', fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.suptitle('Demand Curve of Category Segment : ' + df_initial[df_initial.COD_SKU_CONFIG == SKUid]['CatConcat'].values[0], fontsize=18)\n",
    "plt.title('Product Name: ' + df_initial[df_initial.COD_SKU_CONFIG == SKUid]['DSC_PRODUCT_NAME'].values[0], fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEstimatedLostSale(SKUName,startDate,offlineStartDate,offlineDays,ifPrint):\n",
    "    \n",
    "    if startDate == offlineStartDate:\n",
    "        #print(\"Product Offline\")\n",
    "        return \"Product Offline : \" + str(datetime.strptime(startDate, \"%Y-%m-%d\")) + \" - \" + str(datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1))\n",
    "\n",
    "    PeriodStartDate = startDate\n",
    "    \n",
    "    skuDemandCheckDf = df_initial[df_initial.COD_SKU_CONFIG == SKUName]\n",
    "\n",
    "    skuDemandCheckDf = skuDemandCheckDf[(skuDemandCheckDf.date >= datetime.strptime(PeriodStartDate, \"%Y-%m-%d\")) \n",
    "                     & (skuDemandCheckDf.date <= datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1))]\n",
    "     \n",
    "    if skuDemandCheckDf['COD_SKU_CONFIG'].count() == 0:\n",
    "        #print(\"No Demand\")\n",
    "        return \"No Demand : \" + str(datetime.strptime(startDate, \"%Y-%m-%d\")) + \" - \" + str(datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1))\n",
    "    else:\n",
    "        \n",
    "        categoryName = df_initial[df_initial.COD_SKU_CONFIG == SKUName]['CatConcat'].unique()\n",
    "        \n",
    "        productame = df_initial[df_initial.COD_SKU_CONFIG == SKUName]['DSC_PRODUCT_NAME'].unique()\n",
    "       \n",
    "        brandName = df_initial[df_initial.COD_SKU_CONFIG == SKUName]['DSC_PRODUCT_BRAND_NAME_EN'].unique()\n",
    "        \n",
    "        relevantSkuList = df_initial[(df_initial.CatConcat == categoryName[0]) & (df_initial.COD_SKU_CONFIG != SKUName)]['COD_SKU_CONFIG'].unique()\n",
    "       \n",
    "        releventSKUdataFrame_ = df_prodVisible[(datetime.strptime(PeriodStartDate, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")) : (datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1)).strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "        releventSKUdataFrame_ = releventSKUdataFrame_[releventSKUdataFrame_.columns.intersection(list(relevantSkuList))].apply(pd.Series.value_counts)\n",
    "        \n",
    "        ##If no relevent products found ONLINE during this time period \n",
    "        if len(releventSKUdataFrame_) == 0:\n",
    "            #print(\"Estiamted Lost Sales : Nothing 0\")\n",
    "            return '0'\n",
    "        \n",
    "        findOnlineRelatedSKUs = releventSKUdataFrame_\n",
    "        \n",
    "        findOnlineRelatedSKUs = findOnlineRelatedSKUs.T\n",
    "        \n",
    "        if findOnlineRelatedSKUs.shape[1] == 2:\n",
    "             findOnlineRelatedSKUs.columns = ['Off', 'On']\n",
    "        elif findOnlineRelatedSKUs.shape[1] == 1:\n",
    "             findOnlineRelatedSKUs.columns = ['On']\n",
    "        else :\n",
    "            return \"Error in calculation\"\n",
    "        #Get SKUs from the smilar valid SKU list which were OnLine atleast\n",
    "        similarSKU4DC_ = findOnlineRelatedSKUs[findOnlineRelatedSKUs[\"On\"] > 0].index\n",
    "        \n",
    "        demandCurveDf_ = df_initial[df_initial.COD_SKU_CONFIG.isin(similarSKU4DC_)]\n",
    "        demandCurveDf_ = demandCurveDf_[(demandCurveDf_.date >= datetime.strptime(PeriodStartDate, \"%Y-%m-%d\")) \n",
    "             & (demandCurveDf_.date <= datetime.strptime(offlineStartDate, \"%Y-%m-%d\") + timedelta(days=int(offlineDays)-1))]\n",
    "        \n",
    "        ##When No data found for the relevent Category of the SKU of search\n",
    "        if demandCurveDf_.shape[0] == 0:\n",
    "            #print(\"Estiamted Lost Sales : Null 0\")\n",
    "            return 'Null 0'\n",
    "        \n",
    "        temp = pd.DataFrame(demandCurveDf_.groupby(['date'])['Valid Total'].mean()).reset_index()\n",
    "        demandCurveDf_ = temp['date'].to_frame()\n",
    "        demandCurveDf_['CummulativeQuantity'] = temp['Valid Total'].cumsum().round(1)\n",
    "        demandCurveDf_['DemandPercent'] = (demandCurveDf_['CummulativeQuantity']/demandCurveDf_['CummulativeQuantity'].iloc[-1])*100\n",
    "        #demandCurveDf\n",
    "        \n",
    "        #####Demand Curve for Offlined SKU\n",
    "        demandCurveDf4Offline_ = skuDemandCheckDf['date'].to_frame()\n",
    "        demandCurveDf4Offline_['CummulativeQuantity'] = skuDemandCheckDf[(skuDemandCheckDf.COD_SKU_CONFIG == SKUName)]['Valid Total'].cumsum()\n",
    "        demandCurveDf4Offline_['DemandPercent'] = (demandCurveDf4Offline_['CummulativeQuantity']/demandCurveDf4Offline_['CummulativeQuantity'].iloc[-1])*100\n",
    "        #demandCurveDf4Offline\n",
    "        \n",
    "        #demandCurveDf4Offline[demandCurveDf4Offline.DemandPercent == 100]['date'].values[0]\n",
    "        #demandCurveDf4Offline\n",
    "        #set_trace()\n",
    "        if (datetime.strptime(offlineStartDate, \"%Y-%m-%d\") > demandCurveDf4Offline[demandCurveDf4Offline.DemandPercent == 100]['date']).values[0]:\n",
    "            dateOfOFFLine = offlineStartDate\n",
    "        else:\n",
    "            dateOfOFFLine = demandCurveDf4Offline[demandCurveDf4Offline.DemandPercent == 100]['date'].values[0]\n",
    "\n",
    "        if int(offlineDays) > 1:\n",
    "            DemandPercentWhenSoldOut_ = demandCurveDf_[demandCurveDf_.date <= dateOfOFFLine].tail(1)['DemandPercent']/100\n",
    "        else:\n",
    "            DemandPercentWhenSoldOut_ = demandCurveDf_[demandCurveDf_.date <= dateOfOFFLine][-2:-1]['DemandPercent']/100\n",
    " \n",
    "        ## for case when the Product Category last sold was lesser then the product SKU itself , so we can assume that \n",
    "        ## there is no LOST sale , since SKU was sold after the category Overall was already been soldout .\n",
    "        ## example SKU and dates are 10259FA0924GYNAFAMZ and 4:5 Offline Record \n",
    "        \n",
    "        if DemandPercentWhenSoldOut_.count() == 0:\n",
    "            #print(\"Estiamted Lost Sales : None 0\")\n",
    "            return 'None 0';\n",
    "        \n",
    "        CummulativeQuantityWhenSoldOut_ = demandCurveDf4Offline_[demandCurveDf4Offline_.DemandPercent == 100]['CummulativeQuantity']\n",
    "        \n",
    "        EstiamtedLostSales_ = CummulativeQuantityWhenSoldOut_/DemandPercentWhenSoldOut_.values[0]\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print(\"SKU: \",SKUName ,\" Start Date \",startDate, \" OfflineDate \", offlineStartDate , \" Offline for Days \", offlineDays, \"Demand % : \", DemandPercentWhenSoldOut_.values[0], \"Total Demand when Offline : \", CummulativeQuantityWhenSoldOut_.values[0])\n",
    "        print(\"Estiamted Lost Sales :\", (EstiamtedLostSales_.values[0] - CummulativeQuantityWhenSoldOut_).values[0])\n",
    "        \n",
    "        if ifPrint:\n",
    "            \n",
    "            plt.figure(figsize=(10,7))\n",
    "            markers_on = [DemandPercentWhenSoldOut_.index[0]]\n",
    "            plt.plot(demandCurveDf_.date, demandCurveDf_.DemandPercent,'-bX',markevery=markers_on)\n",
    "\n",
    "            for a,b in zip(demandCurveDf_.date, demandCurveDf_.DemandPercent):\n",
    "                if( b == DemandPercentWhenSoldOut_.values[0] * 100):\n",
    "                    plt.text(a, b, \"Category Demand % : \" + str(b) + \"  \\nDate : \" + str(a))\n",
    "\n",
    "            plt.ylabel('Percentage Demand', fontsize=12)\n",
    "            plt.xlabel('Date', fontsize=12)\n",
    "            plt.suptitle('Demand Curve of Category Segment : ' + df_initial[df_initial.COD_SKU_CONFIG == SKUName]['CatConcat'].values[0], fontsize=18)\n",
    "            plt.title('Product Name: ' + df_initial[df_initial.COD_SKU_CONFIG == SKUName]['DSC_PRODUCT_NAME'].values[0], fontsize=14)\n",
    "\n",
    "        \n",
    "        return (EstiamtedLostSales_.values[0] - CummulativeQuantityWhenSoldOut_).values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.debugger import set_trace\n",
    "getEstimatedLostSale(SKUid,PeriodStartDate,offlineStartDate,offlineDays,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.debugger import set_trace\n",
    "getEstimatedLostSale('10259FA00LZEANAFAMZ','2018-03-13','2018-03-17',45,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.debugger import set_trace\n",
    "getEstimatedLostSale('10454FA1K4RW6NAFAMZ','2018-01-17','2018-03-01',1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = None\n",
    "previousSKU = None\n",
    "currentSKU = None\n",
    "estLostSale = []\n",
    "endDate = None \n",
    "baseStartDate = \"2017-12-01\"\n",
    "import time;\n",
    "\n",
    "localtime = time.time()\n",
    "print(\"Local current time :\", localtime)\n",
    "for i, row in formattedDf[:5000].iterrows():\n",
    "    currentSKU = row['SKU']\n",
    "    if previousSKU == None:\n",
    "        previousSKU = currentSKU\n",
    "    elif previousSKU != currentSKU:\n",
    "        startDate = None\n",
    "        previousSKU = currentSKU\n",
    "        #print(\"SKU Changed .. Updating SKU\")\n",
    "    \n",
    "    if startDate == None:\n",
    "        startDate = datetime.strptime(baseStartDate, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")\n",
    "        #print(\"Start : \",startDate)\n",
    "        endDate = datetime.strptime(row['OfflineDate'], \"%Y-%m-%d\") + timedelta(days=int(row['OfflineDays'])-1)\n",
    "        #print(\"End : \", endDate)\n",
    "    else:\n",
    "        startDate = endDate + timedelta(days=int(1))\n",
    "        #print(\"Start : \",startDate)\n",
    "        delta = startDate - (datetime.strptime(row['OfflineDate'], \"%Y-%m-%d\") + timedelta(days=int(row['OfflineDays'])-1))\n",
    "        delta = delta.days * -1\n",
    "        #print(\"Delta : \", delta)\n",
    "        endDate = (datetime.strptime(startDate.strftime(\"%Y-%m-%d\"), \"%Y-%m-%d\") + timedelta(days=int(delta)))\n",
    "        #endDate = endDate.strftime(\"%Y-%m-%d\")\n",
    "        startDate = startDate.strftime(\"%Y-%m-%d\")\n",
    "        #print(\"End : \", endDate)\n",
    "        \n",
    "    estLostSale.append(getEstimatedLostSale(row['SKU'],startDate,row['OfflineDate'],row['OfflineDays'],False))\n",
    "        \n",
    "\n",
    "    \n",
    "localtime2 = time.time()\n",
    "print(\"total time taken :\", localtime2-localtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facts['pop2050'] = formattedDf[:500].apply(final_pop,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifNumber(s):\n",
    "    try: \n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(estLostSale).shape\n",
    "#pd.DataFrame(estLostSale).to_pickle('./lostSaleEstimates',compression='infer', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([formattedDf[:5000].reset_index(),pd.DataFrame(estLostSale).reset_index()], axis=1) \n",
    "temp.columns = ['index', 'OfflineDate', 'OfflineDays', 'SKU', 'index', 'EstLostSales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['SKU','EstLostSales','OfflineDate', 'OfflineDays' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
